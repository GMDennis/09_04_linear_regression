{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/com09/.local/lib/python3.6/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import scipy\n",
    "import seaborn as seabornInstance \n",
    "from sklearn import metrics\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.datasets import load_iris, load_digits, fetch_mldata, fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 12, 10\n",
    "\n",
    "# Tip: if you want the generated figure to be large, re-run this cell before the beginning of every exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression\n",
    "\n",
    "---------------------------------------\n",
    "\n",
    "## a. Logistic Regression\n",
    "\n",
    "------------------\n",
    "\n",
    "### LogisticRegression(penalty=\"l2\", tol = 1e-4,C=1, solver = \"liblinear\", multi_class=\"ovr\", l1_ratio=None)\n",
    "*  Return a Logistic Regression object.\n",
    " \n",
    "* #### Parameters\n",
    " 1.    penalty: specify the type of norm for regularization\n",
    "     * \"l1\" : L1-norm\n",
    "     * \"l2\" : L2-norm\n",
    "     * \"elasticnet\": elastic regularization\n",
    " 2.    tol: tolerance for stopping criteria, type float\n",
    " 3.  C : a positive float; smaller values specify stronger regularization\n",
    " 4.    solver: algorithm used in the optimization problem\n",
    "     * \"newton-cg\"\n",
    "     * \"lbfgs\"\n",
    "     * \"liblinear\"\n",
    "     * \"sag\"\n",
    "     * \"saga\"\n",
    " 5.    multi_class: a string\n",
    "     * \"ovr\" : binary classification\n",
    "     * \"multinomial\": multinomial loss over a probability distribution, not available when solver='liblinear'\n",
    " 6.    l1_ratio: only applicable when penalty=\"elasticnet\". ratio of l1-regularization. 0 <= l1_ratio <= 1.\n",
    "       if l1_ratio = 1 : equivalent to penalty=\"l1\", if l1_ratio = 1 : equivalent to penalty=\"l2\".\n",
    "     \n",
    "*  #### Attributes (of the LogisticRegression object):\n",
    " *    classses_: a list of class labels known to the classifier.\n",
    " *    coef_: coefficient of the features in the decision function.\n",
    " *    intercept_: intercept (bas) added to the decision function.\n",
    " \n",
    " \n",
    "*  #### Methods (on the LogisticRegression object)\n",
    " *    fit(X, y) : fit the model on the training data.\n",
    " *    get_params: return the parameters for the linear regression estimator.\n",
    " *    predict(X): predict using the linear model\n",
    " *    set_params(): set the parameters of this estimator\n",
    " *    score(X, y): return the mean accuracy on the given test data and labels y.\n",
    " *    predict_proba(X): probability estimates\n",
    " *    sparsity() : convert coefficient matrix to sparse format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-543f16b848d1>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-543f16b848d1>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    print(\" Prediction for the first 3 samples: \", clf.predict(X[:3,:])ㅇ\u001b[0m\n\u001b[0m                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# L1 과 L2 를 모두 더하되, 여기에 scale 곱해서 둘다 넣을 수 있음.\n",
    "# 이런 Regularization 은 정해진 부분에만 적용해도 됨. 비율이나 크기 지정. 이것을 elastic net 이라고 함.\n",
    "# ㅇ\n",
    "\n",
    "# Example: Simple multinomial classification on Iris dataset\n",
    "\n",
    "# Load the dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Define the LogisticRegression object. Note that this is multinomial problem, so we cannot use the default solver.\n",
    "clf = LogisticRegression(solver='lbfgs',multi_class='multinomial', max_iter=1e5)\n",
    "# 단일 class (binary classification) 아니므로 multinomial\n",
    "# Train the Logistic Regression model on the data\n",
    "clf.fit(X,y)\n",
    "\n",
    "# Predict the label of the first 3 samples\n",
    "print(\" Prediction for the first 3 samples: \", clf.predict(X[:3,:])ㅇ\n",
    "\n",
    "# Print the predicted probabilities\n",
    "print(\" Predicted probabilities for the first 3 samples: \", clf.predict_proba(X[:3, :]))\n",
    "\n",
    "# Print the average accuracy:\n",
    "print(\"Accuracy of the model: \", clf.score(X,y)) # 정확도 보여주는 method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Logistic Regression on Digits\n",
    "# Load the data\n",
    "digits = load_digits()\n",
    "\n",
    "# Explore the data\n",
    "print(\"Image Data Shape\" , digits.data.shape)\n",
    "print(\"Label Data Shape\", digits.target.shape)\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "for index, (image, label) in enumerate(zip(digits.data[0:5], digits.target[0:5])):\n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray)\n",
    "    plt.title('Training: %i\\n' % label, fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Logistic Regression on Digits (cont)\n",
    "\n",
    "# Split the train-test sets (will see this function shortly)\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=0)\n",
    "\n",
    "# Logistic Regression\n",
    "### YOUR CODE HERE. Fill in the \"None\"\n",
    "# Hint: define a simple Logistic Regression object with 'lbfgs' solver, 'multinomial' option, AND maximum 10000 iterations\n",
    "logisticRegr = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=10000) #update 10000 times\n",
    "# Hint: train the model on the training set\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "# Hint: 'pred' is the predictions on the test set\n",
    "pred = logisticRegr.predict(x_test)\n",
    "# Hint: 'score' is the accuracy\n",
    "score = logisticRegr.score(x_test, y_test)\n",
    "### END OF YOUR CODE.\n",
    "\n",
    "print(\"Accuracy is: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Logistic Regression on MNIST dataset\n",
    "\n",
    "# Load the data\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "# Some insights into the dataset\n",
    "print(\"Image Data Shape \", X.shape)\n",
    "print(\"Label Data Shape \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Logistic Regression on MNIST dataset (cont)\n",
    "\n",
    "# split the train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=5000, test_size=10000)\n",
    "\n",
    "# Standardization of the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression with L1-regularization\n",
    "### YOUR CODE HERE. Fill in the \"None\".\n",
    "# Hint: define a Logistic Regression object, for multiclass, L1-norm regularization, solver saga, tolerance 0.1 to speed up convergence\n",
    "clf = LogisticRegression(multi_class='multinomial', penalty='l1', solver='saga', tol=0.1)\n",
    "# Hint: fit the model on training data.\n",
    "clf.fit(X_train, y_train)\n",
    "# Hint: 'accuracy' is the accuracy of the model on the test set.\n",
    "l1_score = clf.score(X_test, y_test)\n",
    "### END OF YOR CODE.\n",
    "\n",
    "# Logistic Regression with L2-regularization\n",
    "### YOUR CODE HERE. Fill in the \"None\". 3 lines of code.\n",
    "# Hint: the parameters should be similar to the object defined above.\n",
    "clf2 = LogisticRegression(multi_class='multinomial', penalty='l2', solver='saga', tol=0.1)\n",
    "clf2.fit(X_train, y_train)\n",
    "l2_score = clf2.score(X_test, y_test)\n",
    "### END OF YOUR CODE.\n",
    "\n",
    "\n",
    "print(\"Test score with L1 penalty: %.4f\" % l1_score)\n",
    "print(\"Test score with L2 penalty: %.4f\" % l2_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Logistic Regression on MNIST dataset (cont)\n",
    "# Show some images with their predicted vs. real labels\n",
    "\n",
    "### YOUR CODE HERE. Fill in the 'None'.\n",
    "# Hint: 'predictions' should contain labels predicted for the test images. Either L1-regularized or L2-regularized model is fine.\n",
    "predictions = clf.predict(X_test)\n",
    "### END OF YOUR CODE.\n",
    "\n",
    "index = 0\n",
    "misclassifiedIndexes = []\n",
    "for label, predict in zip(y_test, predictions):\n",
    "    if label != predict: \n",
    "        misclassifiedIndexes.append(index)\n",
    "        index +=1\n",
    "        \n",
    "plt.figure(figsize=(20,4))\n",
    "for plotIndex, badIndex in enumerate(misclassifiedIndexes[0:5]):\n",
    "    plt.subplot(1, 5, plotIndex + 1)\n",
    "    plt.imshow(np.reshape(X_test[badIndex], (28,28)), cmap=plt.cm.gray)\n",
    "    plt.title(\"Predicted: {}, Actual: {}\".format(predictions[badIndex], y_test[badIndex]), fontsize = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that L1-regularization encourages sparsity (many learned coefficients are zero). Let us investigate if it is such the case of Logistic Regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1.00\n",
      "Sparsity with L1 penalty:                6.25%\n",
      "Sparsity with Elastic-Net penalty:       4.69%\n",
      "Sparsity with L2 penalty:                4.69%\n",
      "Score with L1 penalty:                   0.90\n",
      "Score with Elastic-Net penalty:          0.90\n",
      "Score with L2 penalty:                   0.90\n",
      "C=0.10\n",
      "Sparsity with L1 penalty:                29.69%\n",
      "Sparsity with Elastic-Net penalty:       14.06%\n",
      "Sparsity with L2 penalty:                4.69%\n",
      "Score with L1 penalty:                   0.90\n",
      "Score with Elastic-Net penalty:          0.90\n",
      "Score with L2 penalty:                   0.90\n",
      "C=0.01\n",
      "Sparsity with L1 penalty:                84.38%\n",
      "Sparsity with Elastic-Net penalty:       68.75%\n",
      "Sparsity with L2 penalty:                4.69%\n",
      "Score with L1 penalty:                   0.86\n",
      "Score with Elastic-Net penalty:          0.88\n",
      "Score with L2 penalty:                   0.89\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exercise 3: Regularization norms and Sparsity in Logistic Regression\n",
    "\n",
    "# Load the dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "X, y = digits.data, digits.target\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# classify small against large digits\n",
    "y = (y > 4).astype(np.int)\n",
    "\n",
    "l1_ratio = 0.5  # L1 weight in the Elastic-Net regularization\n",
    "\n",
    "fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "# Set regularization parameter\n",
    "for i, (C, axes_row) in enumerate(zip((1, 0.1, 0.01), axes)):\n",
    "    \n",
    "    ### YOUR CODE HERE. Fill in the \"None\".\n",
    "    \n",
    "    # Hint: define 3 Logistic Regression objects, with 3 different regularization methods, tolerance 0.01, solver sage, C is C.\n",
    "    # Hint: you may freely choose the ratio of L1-regularization in elasticnet.\n",
    "    # C 는 1/alpha 에 비례하게 만들어 놓은 parameter.\n",
    "    # SVM 에 C 가 나오는데, C 가 regularization 에 영향을 주는 걸로 나오는데, epsilon 넣어서 soft margin support vector machine 을 쓰는데, \n",
    "    # C 가 커지면 alpha 컸을때랑 정 반대로, regularization 영향이 작아지고, 아니면 커짐.\n",
    "    clf_l1_LR = LogisticRegression(C=C, penalty='l1', tol=0.01, solver='saga')\n",
    "    clf_l2_LR = LogisticRegression(C=C, penalty='l2', tol=0.01, solver='saga')\n",
    "    clf_en_LR = LogisticRegression(C=C, penalty='elasticnet', solver='saga', l1_ratio=l1_ratio, tol=0.01)\n",
    "    \n",
    "    # Hint: train the model on the data \n",
    "    clf_l1_LR.fit(X, y)\n",
    "    clf_l2_LR.fit(X, y)\n",
    "    clf_en_LR.fit(X, y)\n",
    "    \n",
    "    # Hint: apply method ravel() to the trained coefficients.\n",
    "    coef_l1_LR = clf_l1_LR.coef_.ravel()\n",
    "    coef_l2_LR = clf_l2_LR.coef_.ravel()\n",
    "    coef_en_LR = clf_en_LR.coef_.ravel()\n",
    "    \n",
    "    ### END OF YOUR CODE.\n",
    "\n",
    "    # coef_l1_LR contains zeros due to the\n",
    "    # L1 sparsity inducing norm\n",
    "\n",
    "    sparsity_l1_LR = np.mean(coef_l1_LR == 0) * 100\n",
    "    sparsity_l2_LR = np.mean(coef_l2_LR == 0) * 100\n",
    "    sparsity_en_LR = np.mean(coef_en_LR == 0) * 100\n",
    "\n",
    "    print(\"C=%.2f\" % C)\n",
    "    print(\"{:<40} {:.2f}%\".format(\"Sparsity with L1 penalty:\", sparsity_l1_LR))\n",
    "    print(\"{:<40} {:.2f}%\".format(\"Sparsity with Elastic-Net penalty:\",\n",
    "                                  sparsity_en_LR))\n",
    "    print(\"{:<40} {:.2f}%\".format(\"Sparsity with L2 penalty:\", sparsity_l2_LR))\n",
    "    print(\"{:<40} {:.2f}\".format(\"Score with L1 penalty:\",\n",
    "                                 clf_l1_LR.score(X, y)))\n",
    "    print(\"{:<40} {:.2f}\".format(\"Score with Elastic-Net penalty:\",\n",
    "                                 clf_en_LR.score(X, y)))\n",
    "    print(\"{:<40} {:.2f}\".format(\"Score with L2 penalty:\",\n",
    "                                 clf_l2_LR.score(X, y)))\n",
    "\n",
    "    if i == 0:\n",
    "        axes_row[0].set_title(\"L1 penalty\")\n",
    "        axes_row[1].set_title(\"Elastic-Net\\nl1_ratio = %s\" % l1_ratio)\n",
    "        axes_row[2].set_title(\"L2 penalty\")\n",
    "\n",
    "    for ax, coefs in zip(axes_row, [coef_l1_LR, coef_en_LR, coef_l2_LR]):\n",
    "        ax.imshow(np.abs(coefs.reshape(8, 8)), interpolation='nearest', cmap='binary', vmax=1, vmin=0)\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "\n",
    "    axes_row[0].set_ylabel('C = %s' % C)\n",
    "\n",
    "    \n",
    "#weight 의 sparsity 를 계산해본 것. 수치가 regularization 이 커질수록 sparsity 가 늘어남. L1 이 가장 큼.\n",
    "#elastic net 이 그 다음. L1 + L2 term 인데, accuracy 를 어느정도 보존하면서 sparsity 를 올릴 수 있음.\n",
    "#sparsity 없으면 overfitting 에 가깝다?!\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the sparsity percentage and compare between different types of regularization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression\n",
    "\n",
    "---------------------------------------\n",
    "\n",
    "## b. Linear classifier with Stochastic Gradient Descent training\n",
    "\n",
    "------------------\n",
    "\n",
    "### SGDClassificer(loss='hinge', penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=1e-3)\n",
    "*  Return a linear classifier (SVM, Logistic regression,...) with Stochastic Gradient Descent training.\n",
    " \n",
    "* #### Parameters\n",
    " 1.    loss: a string specifying the loss function to use\n",
    "     * \"hinge\": model becomes a linear Support Vector Machine\n",
    "     * \"perceptron\": model becomes Perceptron Algorithm\n",
    "     * \"squared_loss\": linear regression loss.\n",
    "     * \"log\": logistic regression.\n",
    " 2.    penalty: specify the type of norm for regularization\n",
    "     * \"l1\" : L1-norm\n",
    "     * \"l2\" : L2-norm\n",
    "     * \"elasticnet\" elasticnet regularization\n",
    " 3.    alpha: float, weight of the regularization term\n",
    " 4.    l1_ratio: appliable to penalty=\"elasticnet\", ratio of L1-regularization; 1 if only L1 used, 0 if only L2 used\n",
    " 5.    fit_intercept: whether to use intercept. if 'False': data assumed to be already centered.\n",
    " 6.    max_iter: maximum number of iterations\n",
    " 7.    tol: tolerance for stopping criteria, type float\n",
    "     \n",
    " \n",
    "*  #### Attributes (of the SGDClassifier object):\n",
    " *    coef_: estimated coefficients for the linear regression problem.\n",
    " *    intercept_: array of indepentdent term in the linear model.\n",
    " \n",
    "*  #### Methods (on the SGDClassifier object)\n",
    " *    partial_fit(X, y, classes): perform one epoch of stochastic gradient descent on given samples. 'classes' is array of classes.\n",
    " *    fit(X, y) : fit the model on the training data\n",
    " *    get_params: return the parameters for the linear regression estimator.\n",
    " *    predict(X): predict using the linear model\n",
    " *    score(): mean accuracy on the given test data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is:  [1]\n"
     ]
    }
   ],
   "source": [
    "# loss function -> hinge... etc\n",
    "# logistic regression 의 loss 와 log 로 한거랑 완벽히 동일\n",
    "# perceptron -> sigmoid 통과한 것\n",
    "\n",
    "\n",
    "# Example :\n",
    "X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])  # np.ndarray (4L, 2L)\n",
    "y = np.array([1, 1, 2, 2])  # np.ndarray (4L,)\n",
    "\n",
    "# SGD CLassifier\n",
    "# Define a Logistic Regression model, L2-norm regularization, regularization weight 0.0001\n",
    "clf_1 = SGDClassifier(alpha=.0001, loss='log', penalty='l2')\n",
    "\n",
    "# Fit the model on the training set\n",
    "clf_1.fit(X, y)\n",
    "\n",
    "print (\"Prediction is: \", clf_1.predict([[-0.8, -1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is:  [0 1 0 0 1 1 0 0 1 1]\n",
      "Accuracy Score is:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: Simple Logistic Regression with SGDClassifier()\n",
    "\n",
    "np.random.seed(1234)\n",
    "nsamples = 100\n",
    "nfeatures = 1000\n",
    "numOnesInX = np.int(0.01 * nsamples * nfeatures)  # 1000  # <type 'int'>\n",
    "nlabels = 4\n",
    "row_array = np.random.randint(0, nsamples, size=numOnesInX)\n",
    "col_array = np.random.randint(0, nsamples, size=numOnesInX)\n",
    "data = np.ones_like(row_array)\n",
    "\n",
    "# Data\n",
    "X = scipy.sparse.csc_matrix((data, (row_array, col_array)),shape=(nsamples, nfeatures))\n",
    "y = np.random.randint(0, 2, size=[nsamples, nlabels])\n",
    "\n",
    "# Logistic Regression\n",
    "### YOUR CODE HERE. Fill in the \"None\".\n",
    "# Hint: define Logistic Regression with SGDClassifier, regularization weight 0.0001, l2-regularization.\n",
    "clf_2 = SGDClassifier(alpha=.0001, loss='log', penalty='l2')\n",
    "# Hint: perform one epoch of SGD on the first 100 samples of data. Only consider 2 clases.\n",
    "clf_2.partial_fit(X[:100, :], y[:100, 0], classes= [0,1])\n",
    "# Hint: 'pred' is the predicted values on the first 10 samples.\n",
    "pred = clf_2.predict(X[:10, :])\n",
    "### END OF YOUR CODE.\n",
    "\n",
    "# Print the accuracy score.\n",
    "print (\"Prediction is: \", pred)  # [1 1 0 0 1 1 0 0 1 1])\n",
    "print (\"Accuracy Score is: \", accuracy_score(pred, y[:10, 0]))  # gives 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37776, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>username</th>\n",
       "      <th>activity</th>\n",
       "      <th>acceleration_x</th>\n",
       "      <th>acceleration_y</th>\n",
       "      <th>acceleration_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-6-30</td>\n",
       "      <td>13:51:15:847724020</td>\n",
       "      <td>viktor</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>-0.7814</td>\n",
       "      <td>-0.0076</td>\n",
       "      <td>-0.0590</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>-2.9296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-6-30</td>\n",
       "      <td>13:51:16:246945023</td>\n",
       "      <td>viktor</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6722</td>\n",
       "      <td>-1.1233</td>\n",
       "      <td>-0.2344</td>\n",
       "      <td>-0.1757</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-6-30</td>\n",
       "      <td>13:51:16:446233987</td>\n",
       "      <td>viktor</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4399</td>\n",
       "      <td>-1.4817</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>-0.9105</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>-2.4367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-6-30</td>\n",
       "      <td>13:51:16:646117985</td>\n",
       "      <td>viktor</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3031</td>\n",
       "      <td>-0.8125</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>-0.4099</td>\n",
       "      <td>-2.9336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-6-30</td>\n",
       "      <td>13:51:16:846738994</td>\n",
       "      <td>viktor</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4814</td>\n",
       "      <td>-0.9312</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>2.4922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                time username  activity  acceleration_x  \\\n",
       "0  2017-6-30  13:51:15:847724020   viktor         0          0.2650   \n",
       "1  2017-6-30  13:51:16:246945023   viktor         0          0.6722   \n",
       "2  2017-6-30  13:51:16:446233987   viktor         0          0.4399   \n",
       "3  2017-6-30  13:51:16:646117985   viktor         0          0.3031   \n",
       "4  2017-6-30  13:51:16:846738994   viktor         0          0.4814   \n",
       "\n",
       "   acceleration_y  acceleration_z  gyro_x  gyro_y  gyro_z  \n",
       "0         -0.7814         -0.0076 -0.0590  0.0325 -2.9296  \n",
       "1         -1.1233         -0.2344 -0.1757  0.0208  0.1269  \n",
       "2         -1.4817          0.0722 -0.9105  0.1063 -2.4367  \n",
       "3         -0.8125          0.0888  0.1199 -0.4099 -2.9336  \n",
       "4         -0.9312          0.0359  0.0527  0.4379  2.4922  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 2: Different losses applied to SGDClassifier()\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Some insights into the data\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>acceleration_x</th>\n",
       "      <th>acceleration_y</th>\n",
       "      <th>acceleration_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>-0.7814</td>\n",
       "      <td>-0.0076</td>\n",
       "      <td>-0.0590</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>-2.9296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6722</td>\n",
       "      <td>-1.1233</td>\n",
       "      <td>-0.2344</td>\n",
       "      <td>-0.1757</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.4399</td>\n",
       "      <td>-1.4817</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>-0.9105</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>-2.4367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.3031</td>\n",
       "      <td>-0.8125</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>-0.4099</td>\n",
       "      <td>-2.9336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.4814</td>\n",
       "      <td>-0.9312</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>2.4922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity  acceleration_x  acceleration_y  acceleration_z  gyro_x  gyro_y  \\\n",
       "0         0          0.2650         -0.7814         -0.0076 -0.0590  0.0325   \n",
       "1         0          0.6722         -1.1233         -0.2344 -0.1757  0.0208   \n",
       "2         0          0.4399         -1.4817          0.0722 -0.9105  0.1063   \n",
       "3         0          0.3031         -0.8125          0.0888  0.1199 -0.4099   \n",
       "4         0          0.4814         -0.9312          0.0359  0.0527  0.4379   \n",
       "\n",
       "   gyro_z  \n",
       "0 -2.9296  \n",
       "1  0.1269  \n",
       "2 -2.4367  \n",
       "3 -2.9336  \n",
       "4  2.4922  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 2: Different losses applied to SGDClassifier() (cont)\n",
    "\n",
    "# Drop the columns that are not numerical data\n",
    "df = df.drop([\"date\", \"time\", \"username\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8697585768742059\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Different losses applied to SGDClassifier() (cont)\n",
    "\n",
    "# Pre-process the data\n",
    "data = df.values\n",
    "X = data[:, 1:]  # all rows, no label\n",
    "y = data[:, 0]  # all rows, label only\n",
    "\n",
    "# Split the train/test sets, will see this function shortly.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# L2-regularized Linear Support Vector Machine\n",
    "### YOUR CODE HERE. Fill in the \"None\"\n",
    "# Hint: define a L2-regularized Support Vector Machine object by SGDClassifier()\n",
    "model = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "# Hint: fit the model on train set\n",
    "model.fit(X_train, y_train)\n",
    "# Hint: 'accuracy' is the accuracy of the model on the test set\n",
    "accuracy = model.score(X_test, y_test)\n",
    "### END OF YOUR CODE.\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explore the accuracy as a function of the number of iterations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exercise 2: Different losses applied to SGDClassifier() (cont)\n",
    "\n",
    "n_iters = [5, 10, 20, 50, 100, 1000]\n",
    "scores = []\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    for n_iter in n_iters:\n",
    "        ### YOUR CODE HERE. Fill in the \"None\". 3 lines of code.\n",
    "        # Note: at this step, I assume the students are familar with the steps: define object -->> fit -->> score\n",
    "        # Hint: l2-regularized Support Vector Machine, number of iterations is n_iter\n",
    "        # Hint: then fit the model on the train data, and append the accuracy on test data to 'scores'\n",
    "        model = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=n_iter)\n",
    "        model.fit(X_train, y_train)\n",
    "        scores.append(model.score(X_test, y_test))\n",
    "        ### END OF YOUR CODE.\n",
    "\n",
    "plt.title(\"Effect of n_iter\")\n",
    "plt.xlabel(\"n_iter\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.plot(n_iters, scores) \n",
    "plt.show()\n",
    "#n_iter 에 따라서 score 가 증가하다가 다시 떨어짐. overfitting 임.\n",
    "#tol loss 가 줄어든게 0.0001 정도 되면 끊어라. 라는 threshold 임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may get different plots every time you run the cell. However, the general tendency is the accuracy improves as n_iter increases, and will converge at some point.\n",
    "\n",
    "Let us also experiment on how accuracy changes if we apply different loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exercise 2: Different losses applied to SGDClassifier() (cont)\n",
    "losses = [\"hinge\", \"log\", \"modified_huber\", \"perceptron\", \"squared_hinge\"]\n",
    "scores = []\n",
    "for loss in losses:\n",
    "    ### YOUR CODE HERE. Fill in the \"None\".\n",
    "    # Hint: 1000 iterations, L2-regularization, try out all loss functions given in 'losses'.\n",
    "    model = SGDClassifier(loss=loss, penalty=\"l2\", max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    scores.append(model.score(X_test, y_test))\n",
    "    ### END OF YOUR CODE.\n",
    "\n",
    "plt.title(\"Effect of loss function\")\n",
    "plt.xlabel(\"loss function\")\n",
    "plt.ylabel(\"score\")\n",
    "x = np.arange(len(losses))\n",
    "plt.xticks(x, losses)\n",
    "plt.plot(x, scores) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "1. https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model\n",
    "2. https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a\n",
    "3. https://github.com/WilliamQLiu/python-examples/blob/master/sklearn/SGDClassifier_example.py\n",
    "4. https://www.kaggle.com/vmalyi/run-or-walk/downloads/dataset.csv/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the end of Logistic Regression section for today tutorials! In the next part, we will see how some hyper-parameters can be chosen to optimize the performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
